{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ab29148-96da-49fd-a172-3d829b6ce1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install PyMuPDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2288cffa-2768-4af2-9d0b-e89e0dc1d917",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "362c8abe-e0e9-4ccf-b607-c6a59902ecb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install py-pdf-parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9270be9-8d0f-4b9e-9021-0f9384e2f700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import fitz \n",
    "# https://www.geeksforgeeks.org/extract-text-from-pdf-file-using-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f14d5ca2-7e62-4142-b703-a5b26222b656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc = fitz.open(\"think_bayes_trunc.pdf\")\n",
    "# type(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f82b54a3-39c9-4b2e-be41-6202e8e81348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text = ''\n",
    "# # for page in doc:\n",
    "#     text = page.get_text()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34188f44-531b-4268-9582-d269e24be005",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# text #very long outputvv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7974c68-1b59-4142-80f9-1d50cba555c4",
   "metadata": {},
   "source": [
    "# trying out PyPDF Parser to collect headings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ecbed86-4aa2-464f-8712-0695ab3684de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install py-pdf-parser[dev]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "33a84cd0-7b72-4acf-a46e-457d5a289f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "015f46b5-67e8-4ac5-8ec8-264132264219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from py_pdf_parser.loaders import load_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d0280083-df7c-42e7-b67d-393afefa362b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from py_pdf_parser.visualise import visualise\n",
    "# this is bogus bc i need to install the dev vers of py_pdf_parser which doesnt exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "96df2f3c-705e-4648-9c8d-481768d3a528",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pdfParse = load_file(\"think_bayes_trunc.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "99b00d05-ac6c-41b4-bef7-89fbb439411a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for elem in pdfParse.elements:\n",
    "#     print(elem.font)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6d2252-7be6-487b-8a00-2de40b04925b",
   "metadata": {},
   "source": [
    "### it works and i get fonts, but without the visualizer, I can't use this library to its full capabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1adf5c-df91-4226-a3cf-6b470e40cd05",
   "metadata": {},
   "source": [
    "# take 2: rather than parsing the data, can i just give the model a blob?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "da170137-07f8-473e-9a0e-155587f18e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import fitz \n",
    "# https://www.geeksforgeeks.org/extract-text-from-pdf-file-using-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "289f2b24-6520-43dd-a19e-4341d24a2c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_ds(data, doc_title, count, sample_size, document):\n",
    "    for page in document:\n",
    "        # print(\"len\" + str(text_df.shape))\n",
    "        text = page.get_text()\n",
    "        if len(text) > sample_size:\n",
    "            add_in_sections(data, doc_title, text, sample_size, count)\n",
    "            count +=1\n",
    "        else:\n",
    "            data.loc[data.shape[0]-1] = [doc_title, count, text, 1.0]\n",
    "            count +=1 \n",
    "    return data\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "feeab35f-9d59-41db-bb28-c5436307b6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_in_sections(data, doc_title, text, sample_size, count):\n",
    "    if len(text) != 0:\n",
    "        if sample_size < len(text):\n",
    "            data.loc[data.shape[0]-1] = [doc_title, count, text[:len(text)], 1.0]\n",
    "            count +=1\n",
    "            add_in_sections(data, doc_title, text[sample_size:], sample_size, count)\n",
    "        else:\n",
    "            data.loc[data.shape[0]-1] = [doc_title, count, text[:sample_size], 1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a148febc-cf14-4a58-97bc-4c5ef26c047d",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_train = fitz.open(\"think_bayes_train.pdf\")\n",
    "text_df = pd.DataFrame(columns=[\"title\", \"count\", \"body\", \"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ffccec0b-1b7d-4787-8ea4-4d7140b0642a",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_df = make_ds(text_df, \"Thinking Bayes: Bayesian Statistics in Python\", 0, 520, doc_train)\n",
    "#520 max sample length for roberta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "043ee155-f624-44ae-9302-c43e783e1d31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>count</th>\n",
       "      <th>body</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-1</th>\n",
       "      <td>Thinking Bayes: Bayesian Statistics in Python</td>\n",
       "      <td>0</td>\n",
       "      <td>Allen B. Downey\\nSecond \\nEdition\\nThink  \\n B...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Thinking Bayes: Bayesian Statistics in Python</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Thinking Bayes: Bayesian Statistics in Python</td>\n",
       "      <td>2</td>\n",
       "      <td>Allen B. Downey\\nThink Bayes\\nBayesian Statist...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Thinking Bayes: Bayesian Statistics in Python</td>\n",
       "      <td>3</td>\n",
       "      <td>978-1-492-08946-9\\n[LSI]\\nThink Bayes\\nby Alle...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Thinking Bayes: Bayesian Statistics in Python</td>\n",
       "      <td>4</td>\n",
       "      <td>tions Editor: Jessica Haberman\\nDevelopment Ed...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            title  count  \\\n",
       "-1  Thinking Bayes: Bayesian Statistics in Python      0   \n",
       " 0  Thinking Bayes: Bayesian Statistics in Python      1   \n",
       " 1  Thinking Bayes: Bayesian Statistics in Python      2   \n",
       " 2  Thinking Bayes: Bayesian Statistics in Python      3   \n",
       " 3  Thinking Bayes: Bayesian Statistics in Python      4   \n",
       "\n",
       "                                                 body  labels  \n",
       "-1  Allen B. Downey\\nSecond \\nEdition\\nThink  \\n B...     1.0  \n",
       " 0                                                        1.0  \n",
       " 1  Allen B. Downey\\nThink Bayes\\nBayesian Statist...     1.0  \n",
       " 2  978-1-492-08946-9\\n[LSI]\\nThink Bayes\\nby Alle...     1.0  \n",
       " 3  tions Editor: Jessica Haberman\\nDevelopment Ed...     1.0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287ba005-ec9c-49b9-9d93-1c11109bc843",
   "metadata": {},
   "source": [
    "## start tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3c7f1488-5391-4812-9bd1-134c3f7e6ec5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /Users/abinayadinesh/opt/anaconda3/lib/python3.9/site-packages (2.8.0)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in /Users/abinayadinesh/opt/anaconda3/lib/python3.9/site-packages (from datasets) (10.0.1)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /Users/abinayadinesh/opt/anaconda3/lib/python3.9/site-packages (from datasets) (2022.7.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/abinayadinesh/opt/anaconda3/lib/python3.9/site-packages (from datasets) (6.0)\n",
      "Requirement already satisfied: dill<0.3.7 in /Users/abinayadinesh/opt/anaconda3/lib/python3.9/site-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /Users/abinayadinesh/opt/anaconda3/lib/python3.9/site-packages (from datasets) (4.64.1)\n",
      "Requirement already satisfied: aiohttp in /Users/abinayadinesh/opt/anaconda3/lib/python3.9/site-packages (from datasets) (3.8.3)\n",
      "Requirement already satisfied: responses<0.19 in /Users/abinayadinesh/opt/anaconda3/lib/python3.9/site-packages (from datasets) (0.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/abinayadinesh/opt/anaconda3/lib/python3.9/site-packages (from datasets) (1.21.5)\n",
      "Requirement already satisfied: packaging in /Users/abinayadinesh/opt/anaconda3/lib/python3.9/site-packages (from datasets) (21.3)\n",
      "Requirement already satisfied: multiprocess in /Users/abinayadinesh/opt/anaconda3/lib/python3.9/site-packages (from datasets) (0.70.14)\n",
      "Requirement already satisfied: xxhash in /Users/abinayadinesh/opt/anaconda3/lib/python3.9/site-packages (from datasets) (3.2.0)\n",
      "Requirement already satisfied: pandas in /Users/abinayadinesh/opt/anaconda3/lib/python3.9/site-packages (from datasets) (1.4.4)\n",
      "Requirement already satisfied: requests>=2.19.0 in /Users/abinayadinesh/opt/anaconda3/lib/python3.9/site-packages (from datasets) (2.28.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /Users/abinayadinesh/opt/anaconda3/lib/python3.9/site-packages (from datasets) (0.11.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/abinayadinesh/opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (4.3.0)\n",
      "Requirement already satisfied: filelock in /Users/abinayadinesh/opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.6.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/abinayadinesh/opt/anaconda3/lib/python3.9/site-packages (from packaging->datasets) (3.0.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/abinayadinesh/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/abinayadinesh/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (1.26.11)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/abinayadinesh/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/abinayadinesh/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (2022.9.24)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/abinayadinesh/opt/anaconda3/lib/python3.9/site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/abinayadinesh/opt/anaconda3/lib/python3.9/site-packages (from aiohttp->datasets) (21.4.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/abinayadinesh/opt/anaconda3/lib/python3.9/site-packages (from aiohttp->datasets) (1.8.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/abinayadinesh/opt/anaconda3/lib/python3.9/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/abinayadinesh/opt/anaconda3/lib/python3.9/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/abinayadinesh/opt/anaconda3/lib/python3.9/site-packages (from aiohttp->datasets) (1.3.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/abinayadinesh/opt/anaconda3/lib/python3.9/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/abinayadinesh/opt/anaconda3/lib/python3.9/site-packages (from pandas->datasets) (2022.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/abinayadinesh/opt/anaconda3/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e689355d-06b1-4ec2-96f2-031e57eeb148",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /Users/abinayadinesh/opt/anaconda3/lib/python3.9/site-packages (4.25.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/abinayadinesh/opt/anaconda3/lib/python3.9/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/abinayadinesh/opt/anaconda3/lib/python3.9/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/abinayadinesh/opt/anaconda3/lib/python3.9/site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: requests in /Users/abinayadinesh/opt/anaconda3/lib/python3.9/site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/abinayadinesh/opt/anaconda3/lib/python3.9/site-packages (from transformers) (1.21.5)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /Users/abinayadinesh/opt/anaconda3/lib/python3.9/site-packages (from transformers) (0.13.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /Users/abinayadinesh/opt/anaconda3/lib/python3.9/site-packages (from transformers) (0.11.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/abinayadinesh/opt/anaconda3/lib/python3.9/site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: filelock in /Users/abinayadinesh/opt/anaconda3/lib/python3.9/site-packages (from transformers) (3.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/abinayadinesh/opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.3.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/abinayadinesh/opt/anaconda3/lib/python3.9/site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/abinayadinesh/opt/anaconda3/lib/python3.9/site-packages (from requests->transformers) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/abinayadinesh/opt/anaconda3/lib/python3.9/site-packages (from requests->transformers) (2022.9.24)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/abinayadinesh/opt/anaconda3/lib/python3.9/site-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/abinayadinesh/opt/anaconda3/lib/python3.9/site-packages (from requests->transformers) (2.0.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1dd49cc2-7fb8-495c-893f-58c0be9967d2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentencepiece in /Users/abinayadinesh/opt/anaconda3/lib/python3.9/site-packages (0.1.97)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "91f38838-4fcf-4897-944e-e95fd8467e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset,DatasetDict\n",
    "#turn our pandas dataframe into a huggingface dataset to do huggingface things with it\n",
    "text_ds = Dataset.from_pandas(text_df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "00a3a3d8-3e2e-48f0-ab37-1de232761e0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['title', 'count', 'body', 'labels', '__index_level_0__'],\n",
       "    num_rows: 864\n",
       "})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "009e677e-b59c-4c30-90f6-ead470ff15ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_nm = 'microsoft/deberta-v3-small'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e20e7e21-97e6-4441-9daa-944649ac8575",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-14 15:18:59.291570: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "/Users/abinayadinesh/opt/anaconda3/lib/python3.9/site-packages/transformers/convert_slow_tokenizer.py:446: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification,AutoTokenizer\n",
    "tokz = AutoTokenizer.from_pretrained(model_nm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ea415188-b2f2-4ba6-943e-f88ce9c51020",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.models.deberta_v2.tokenization_deberta_v2_fast.DebertaV2TokenizerFast"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tokz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2f9967ff-1767-42ce-b121-b6e21b4d6d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize our inputs\n",
    "def tok_func(x):\n",
    "    return tokz(x['body'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "34e9b048-ab91-4ae2-8dfb-67ffdf1071ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "596ec9b9610c4802858b76e960d31a54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tok_text_ds = text_ds.map(tok_func, batched=True)\n",
    "# ds = Dataset.from_pandas(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a660c09b-89e2-42de-9d28-c8db15e5712e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datasets.arrow_dataset.Dataset"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tok_text_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dbf238b7-71dd-4c53-938d-367f7217ccf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['title', 'count', 'body', 'labels', '__index_level_0__', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 648\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['title', 'count', 'body', 'labels', '__index_level_0__', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 216\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dds = tok_text_ds.train_test_split(0.25, seed=42)\n",
    "dds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef8f52e-4769-49fb-8c00-95b77241b7c4",
   "metadata": {},
   "source": [
    "### load test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "027858e9-37f4-44ec-9df5-5be095509136",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_test = fitz.open(\"think_bayes_test.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f6cf6653-2729-4bb7-9088-c1aa2b241dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df = pd.DataFrame(columns=[\"title\", \"count\", \"body\", \"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9dbde748-06c2-4e3d-bdb7-bdc287a10fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df = make_ds(eval_df, \"Thinking Bayes: Bayesian Statistics in Python\", 1245, 520, doc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ed4256b0-6485-4c46-8930-9dcdeaea565c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>count</th>\n",
       "      <th>body</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-1</th>\n",
       "      <td>Thinking Bayes: Bayesian Statistics in Python</td>\n",
       "      <td>1245</td>\n",
       "      <td>CHAPTER 15\\nMark and Recapture\\nThis chapter i...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Thinking Bayes: Bayesian Statistics in Python</td>\n",
       "      <td>1246</td>\n",
       "      <td>ll work with models that have three parameters...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Thinking Bayes: Bayesian Statistics in Python</td>\n",
       "      <td>1247</td>\n",
       "      <td>ng the hair samples, the researchers\\nuse DNA ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Thinking Bayes: Bayesian Statistics in Python</td>\n",
       "      <td>1246</td>\n",
       "      <td>To estimate the population of bears from this ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Thinking Bayes: Bayesian Statistics in Python</td>\n",
       "      <td>1247</td>\n",
       "      <td>0 bears have been identified. During the secon...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            title  count  \\\n",
       "-1  Thinking Bayes: Bayesian Statistics in Python   1245   \n",
       " 0  Thinking Bayes: Bayesian Statistics in Python   1246   \n",
       " 1  Thinking Bayes: Bayesian Statistics in Python   1247   \n",
       " 2  Thinking Bayes: Bayesian Statistics in Python   1246   \n",
       " 3  Thinking Bayes: Bayesian Statistics in Python   1247   \n",
       "\n",
       "                                                 body  labels  \n",
       "-1  CHAPTER 15\\nMark and Recapture\\nThis chapter i...     1.0  \n",
       " 0  ll work with models that have three parameters...     1.0  \n",
       " 1  ng the hair samples, the researchers\\nuse DNA ...     1.0  \n",
       " 2  To estimate the population of bears from this ...     1.0  \n",
       " 3  0 bears have been identified. During the secon...     1.0  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "833b1356-52c6-4270-aa0f-27bdfa42eb4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "967e87224a9a4dbb9ef2ff9356100893",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval_ds = Dataset.from_pandas(eval_df).map(tok_func, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a8533fb6-8cf4-41d7-a727-f9b918fc6750",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['title', 'count', 'body', 'labels', '__index_level_0__', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 381\n",
       "})"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6e0791-e303-425e-8692-18c98f36e605",
   "metadata": {},
   "source": [
    "# Train Our Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "723d5aa7-c39f-4811-9aaa-155f40b81b8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Requirement already satisfied: torch in /Users/abinayadinesh/opt/anaconda3/lib/python3.9/site-packages (1.13.1)\n",
      "Requirement already satisfied: typing-extensions in /Users/abinayadinesh/opt/anaconda3/lib/python3.9/site-packages (from torch) (4.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c937768b-da6c-4e3a-926f-685fe8036610",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr_d(eval_pred): return {'pearson': corr(*eval_pred)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "00987b69-4e38-4c5a-908d-930ecf51af1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer, AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "675330a6-6cc9-4213-9a39-73534e32eac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 128\n",
    "epochs = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "82cdfa9f-c277-4762-8776-5a953d72446b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 8e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3c93f0f6-c3a4-4e1b-8104-594ae9351af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = TrainingArguments('outputs', learning_rate=lr, warmup_ratio=0.1, lr_scheduler_type='cosine',\n",
    "    evaluation_strategy=\"epoch\", per_device_train_batch_size=bs, per_device_eval_batch_size=bs*2,\n",
    "    num_train_epochs=epochs, weight_decay=0.01, report_to='none')\n",
    "# warmup ratio is the same as fit_one_cycle in fast ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "46af1445-fae2-439f-bf2b-9ed0327c3e42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-v3-small were not used when initializing DebertaV2ForSequenceClassification: ['mask_predictions.dense.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.classifier.bias', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.dense.weight', 'mask_predictions.classifier.weight', 'mask_predictions.LayerNorm.bias']\n",
      "- This IS expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-small and are newly initialized: ['pooler.dense.bias', 'classifier.weight', 'pooler.dense.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(model_nm, num_labels=1)\n",
    "trainer = Trainer(model, args, train_dataset=dds['train'], eval_dataset=dds['test'], compute_metrics=corr_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce459fd7-ded4-4a92-b2e2-7a93ea623dd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: count, __index_level_0__, title, body. If count, __index_level_0__, title, body are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/Users/abinayadinesh/opt/anaconda3/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 648\n",
      "  Num Epochs = 4\n",
      "  Instantaneous batch size per device = 128\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 24\n",
      "  Number of trainable parameters = 141895681\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5382191-2712-445a-aa32-628707c1d7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = trainer.predict(eval_ds).predictions.astype(float)\n",
    "preds"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
